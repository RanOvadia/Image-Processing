{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OjC6tssoDzCn",
        "BopEioyJIePb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup \n",
        "Run this first, it should crash the colab but its fine !"
      ],
      "metadata": {
        "id": "OjC6tssoDzCn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz28PfOuDXkg",
        "outputId": "31c13efb-bb7a-4483-fffa-d78ee3bdb816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.4/454.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.4.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.4 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.1 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# run terminal comomands\n",
        "!pip install -U -qq tensorflow==2.5.0\n",
        "exit() # Runtime restart required!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Configuration \n",
        "Run this second, it will configure the model and make it ready to use"
      ],
      "metadata": {
        "id": "BopEioyJIePb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libs\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "!git clone https://github.com/deedeeharris/Mask_RCNN\n",
        "\n",
        "ROOT_DIR = 'Mask_RCNN'\n",
        "\n",
        "sys.path.append(ROOT_DIR) \n",
        "from mrcnn.config import Config\n",
        "import mrcnn.utils as utils\n",
        "from mrcnn import visualize\n",
        "import mrcnn.model as modellib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hWLiA-gETGt",
        "outputId": "d4d44096-a6aa-4cd6-87bf-2929c0dfa61f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mask_RCNN'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 66 (delta 28), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), 465.52 KiB | 1.97 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainConfig(Config):\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"custom\"\n",
        "\n",
        "    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 5\n",
        "\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    # Number of classes (including background) - IMPORTANT TO CHANGE ACCORDING TO YOUR LABELS IN YOUR JSON\n",
        "    NUM_CLASSES = 1 + 2  # background + (red + green)\n",
        "\n",
        "    # All of our training images are 1920x1012\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    \n",
        "    # Matterport originally used resnet101, but I downsized to fit it on my graphics card\n",
        "    BACKBONE = 'resnet50' # resnet50\n",
        "\n",
        "    # To be honest, I haven't taken the time to figure out what these do\n",
        "    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    MAX_GT_INSTANCES = 50 \n",
        "    POST_NMS_ROIS_INFERENCE = 500 \n",
        "    POST_NMS_ROIS_TRAINING = 1000 \n",
        "    \n",
        "config = TrainConfig()"
      ],
      "metadata": {
        "id": "vKeaGnNeEZek"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the trained model (red vs green flowers)\n",
        "!pip install -U --no-cache-dir gdown --pre -qq\n",
        "\n",
        "import gdown\n",
        "\n",
        "file_id = '1fMYMGNEQstJ6WyagIyLWRmn-gyy6AsR5'\n",
        "model_filename = 'mask_rcnn_redvsgreen_0030.h5'\n",
        "gdown.download(f'https://drive.google.com/u/0/uc?id={file_id}', model_filename)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Qrl8vviyFBng",
        "outputId": "5c385cb1-88e3-4d00-f1b0-2f24610b2ce8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1fMYMGNEQstJ6WyagIyLWRmn-gyy6AsR5\n",
            "To: /content/mask_rcnn_redvsgreen_0030.h5\n",
            "100%|██████████| 185M/185M [00:02<00:00, 69.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mask_rcnn_redvsgreen_0030.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jsonTrain_file_id = '15dvrffNeDWe0LAe8EkY_R7l50khtAfqQ'\n",
        "jsonTrain_filename = 'train.json'\n",
        "gdown.download(f'https://drive.google.com/u/0/uc?id={jsonTrain_file_id}', jsonTrain_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rfIW24QpHy6V",
        "outputId": "a4fbb976-15f8-4b29-adf0-1def3ba43360"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=15dvrffNeDWe0LAe8EkY_R7l50khtAfqQ\n",
            "To: /content/train.json\n",
            "100%|██████████| 75.2k/75.2k [00:00<00:00, 63.7MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InferenceConfig(TrainConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9 # CHANGE HERE IF YOU WANT\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "test_model = modellib.MaskRCNN(\n",
        "    mode=\"inference\", \n",
        "    config=inference_config,\n",
        "    model_dir='/content')\n",
        "\n",
        "model_path = f'/content/{model_filename}'\n",
        "print(model_path)\n",
        "\n",
        "test_model.load_weights(model_path, by_name=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWkE1a2iFhUw",
        "outputId": "12611f46-6265-4c98-d073-82ed2ceb5364"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mask_rcnn_redvsgreen_0030.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CocoLikeDataset(utils.Dataset):\n",
        "    \"\"\" Generates a COCO-like dataset, i.e. an image dataset annotated in the style of the COCO dataset.\n",
        "        See http://cocodataset.org/#home for more information.\n",
        "    \"\"\"\n",
        "    def load_data(self, annotation_json, images_dir):\n",
        "        \"\"\" Load the coco-like dataset from json\n",
        "        Args:\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "        # Load json from file\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "        \n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(class_name))\n",
        "                return\n",
        "            \n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "        \n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "        \n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "                \n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "                \n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "                \n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "        \n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "        \n",
        "        return mask, class_ids"
      ],
      "metadata": {
        "id": "Zy30ZqNXFs2e"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get classnames\n",
        "dataset_train = CocoLikeDataset()\n",
        "dataset_train.load_data('/content/train.json', '/content')\n",
        "dataset_train.prepare()\n",
        "class_names = dataset_train.class_names"
      ],
      "metadata": {
        "id": "Xfiqv01SF0Q1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "\n",
        "mask_colors = [\n",
        "    (0., 0., 0.), # Background\n",
        "    (1., 0., 0.), # Red\n",
        "    (0., 1., 0.)  # Green\n",
        "]\n",
        "\n",
        "\n",
        "def mask_image(img):\n",
        "  img_arr = np.array(img)\n",
        "\n",
        "  results = test_model.detect([img_arr], verbose=1)\n",
        "  r = results[0]\n",
        "\n",
        "  colors = tuple(np.take(mask_colors, r['class_ids'], axis=0))\n",
        "\n",
        "  visualize.display_instances(img, r['rois'], r['masks'], r['class_ids'], \n",
        "                              class_names, r['scores'], figsize=(16, 8), \n",
        "                              colors=colors)\n",
        "  return r"
      ],
      "metadata": {
        "id": "k4zNNgmCFpLm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Upload image !\n",
        "Upload your bell pepper image ! \n",
        "For better results, keep the picture simple with out many background objects.\n",
        "\n",
        "Click on the start below ->"
      ],
      "metadata": {
        "id": "obX4tPzIImMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload image\n",
        "\n",
        "# libs\n",
        "from google.colab import files\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io\n",
        "\n",
        "# upload an image \n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "img = io.imread(img_path)\n",
        "\n",
        "# call our function\n",
        "result = mask_image(img) "
      ],
      "metadata": {
        "id": "73GgYZubIpV6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model Results\n",
        "Run this after you upload your picture and get the visualisation\n",
        "\n",
        "(results in the output below)"
      ],
      "metadata": {
        "id": "TzrUT7h4JKDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "totalFruits = len(result['class_ids'])\n",
        "ripe = 0\n",
        "for fruit in result['class_ids']:\n",
        "  if fruit == 1:\n",
        "    ripe+=1\n",
        "\n",
        "if totalFruits == 0:\n",
        "  print('Aint no fruits on this plant !')\n",
        "else:\n",
        "  precent=(ripe/totalFruits)*100\n",
        "  print(\"Fruit number is \"+str(totalFruits) + \"\\nRipe fruits precentage is: \"+ str(int(precent))+'%')\n"
      ],
      "metadata": {
        "id": "5m6mExXIJlUP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}